# gradio_ui.pyï¼ˆDay7ï¼šä½¿ç”¨ç¼“å­˜æ¨¡å‹æ’­æŠ¥ï¼‰
import gradio as gr
import os
import json
from PIL import Image

# ===== ä¿®å¤ PyTorch æƒé‡åŠ è½½é™åˆ¶ =====
import torch
try:
    from TTS.utils.radam import RAdam  # æ­£ç¡®å¼•å…¥ RAdam ç±»
    torch.serialization.add_safe_globals({"TTS.utils.radam.RAdam": RAdam})
    print("[INFO] å·²å…è®¸ RAdam åŠ è½½")
except Exception as e:
    print("[WARN] æ— æ³•è®¾ç½® safe_globalsï¼š", e)

# ===== ä½¿ç”¨ç¼“å­˜æ¨¡å‹åŠ è½½ TTS =====
try:
    from TTS.api import TTS
    tts = TTS(model_name="tts_models/zh-CN/baker/tacotron2-DDC-GST", progress_bar=False, gpu=False)
    print("[INFO] æˆåŠŸåŠ è½½ç¼“å­˜æ¨¡å‹ï¼štts_models/zh-CN/baker/tacotron2-DDC-GST")
except Exception as e:
    print("[ERROR] TTS æ¨¡å‹åŠ è½½å¤±è´¥ï¼š", e)
    tts = None

# ===== æ•°æ®è·¯å¾„ =====
qa_path = "/root/autodl-tmp/Multimodal_heritage/data/qa_results.json"
image_dir = "/root/autodl-tmp/Multimodal_heritage/data/images"
audio_output_path = "/root/autodl-tmp/Multimodal_heritage/data/description_audio.wav"

# ===== åŠ è½½é—®ç­”ç»“æœ =====
with open(qa_path, encoding="utf-8") as f:
    qa_data = json.load(f)

image_dict = {entry["image_id"]: entry for entry in qa_data}

# ===== åˆæˆè¯­éŸ³å‡½æ•° =====
def speak_text(text):
    if not tts:
        print("[WARN] TTS æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡è¯­éŸ³åˆæˆã€‚")
        return None
    try:
        tts.tts_to_file(text=text, file_path=audio_output_path)
        print(f"[INFO] è¯­éŸ³æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼š{audio_output_path}")
        return audio_output_path
    except Exception as e:
        print("[ERROR] åˆæˆå¤±è´¥ï¼š", e)
        return None

# ===== ä¸»å±•ç¤ºå‡½æ•° =====
def show_info(image_id):
    entry = image_dict[image_id]
    img_path = os.path.join(image_dir, image_id)
    image = Image.open(img_path).convert("RGB")

    description = entry.get("description", "")
    qa_text = "\n\n".join([f"Q: {q['question']}\nA: {q['answer']}" for q in entry.get("qa_pairs", [])])
    knowledge = entry.get("knowledge", "æš‚æ— åŒ¹é…æ®µè½")

    audio = speak_text(description)

    return image, description, qa_text, knowledge, audio

# ===== Gradio UI ç•Œé¢æ„å»º =====
dropdown = gr.Dropdown(choices=list(image_dict.keys()), label="é€‰æ‹©å›¾ç‰‡")
image_display = gr.Image(type="pil", label="å›¾åƒå±•ç¤º")
description_box = gr.Textbox(label="å›¾åƒæè¿°")
qa_box = gr.Textbox(label="é—®ç­”å†…å®¹")
knowledge_box = gr.Textbox(label="ğŸ“– åŒ¹é…çŸ¥è¯†æ®µè½")
audio_box = gr.Audio(label="ğŸ”Š å›¾åƒè¯´æ˜è¯­éŸ³æ’­æ”¾", type="filepath")

interface = gr.Interface(
    fn=show_info,
    inputs=dropdown,
    outputs=[image_display, description_box, qa_box, knowledge_box, audio_box],
    title="å¤šæ¨¡æ€æ–‡åŒ–é—äº§å±•ç¤ºç³»ç»Ÿ",
    description="é€‰æ‹©å›¾åƒåï¼Œå°†å±•ç¤ºå…¶æè¿°ã€é—®ç­”ç»“æœã€åŒ¹é…çŸ¥è¯†æ®µè½å’Œè¯­éŸ³æ’­æŠ¥"
)

if __name__ == "__main__":
    interface.launch(server_name="0.0.0.0", server_port=7860, share=False)
